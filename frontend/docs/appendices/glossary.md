---
sidebar_position: 9
title: "Appendix I: Glossary"
---

# Appendix I: Glossary

This glossary provides definitions for key terms used throughout the Physical AI and Humanoid Robotics course. Understanding these terms is essential for effective communication and comprehension of the concepts covered.

## A

**Actuator**: A device that converts control signals into physical movement. In humanoid robots, actuators drive joints to produce motion.

**Affordance**: The possibility of action offered by an object or environment to an agent. For example, a handle affords grasping.

**AI (Artificial Intelligence)**: The simulation of human intelligence processes by machines, especially computer systems. In robotics, AI enables perception, decision-making, and learning.

**Anthropomorphism**: The attribution of human characteristics or behavior to non-human entities, such as robots.

**Articulated Robot**: A robot with rotary joints, similar to a human arm. The joints can either be revolute (rotary) or prismatic (linear).

**Autonomous System**: A system that can operate independently without human intervention, making decisions based on its programming and sensor inputs.

## B

**Behavior Tree**: A hierarchical structure used to represent and control the behavior of autonomous agents in robotics and AI.

**Biomechanics**: The study of the structure, function, and motion of the mechanical aspects of biological systems, particularly relevant for humanoid robot design.

**Biometric**: A measurable physical characteristic or personal behavioral trait used to recognize or verify the identity of individuals.

**Bipedal Locomotion**: Two-legged walking motion, a key capability for humanoid robots.

**Braitenberg Vehicle**: A conceptual model for reactive robot control, demonstrating how simple sensor-motor connections can produce complex behaviors.

## C

**Cartesian Coordinates**: A coordinate system that specifies each point uniquely in a plane by a pair of numerical coordinates, used in robotics for position specification.

**Center of Mass (COM)**: The point in an object where all the mass can be considered to be concentrated for the purpose of analyzing motion.

**Closed-Loop Control**: A control system that uses feedback to adjust its output, comparing the actual output with the desired output.

**Cognitive Architecture**: An abstract framework defining the structure of cognitive systems, used to model human-like intelligence in robots.

**Collaborative Robot (Cobot)**: A robot designed to work safely alongside humans in a shared workspace.

**Collision Detection**: The computational problem of detecting the intersection of two or more objects, crucial for robot safety.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

**Control Theory**: An engineering and mathematics field dealing with the behavior of dynamical systems with inputs, and how their behavior is modified by feedback.

**Convolutional Neural Network (CNN)**: A class of deep neural networks, most commonly applied to analyzing visual imagery.

## D

**Deep Learning**: A subset of machine learning based on artificial neural networks with representation learning, enabling complex pattern recognition.

**Degree of Freedom (DOF)**: The number of independent movements a mechanical system can make, typically referring to independent joint axes in robotics.

**Dexterous Manipulation**: Fine motor control allowing robots to manipulate objects with precision, similar to human hand dexterity.

**Digital Twin**: A virtual representation of a physical system that mirrors its properties, states, and behaviors in real-time.

**Domain Randomization**: A technique for training AI models by randomizing simulation parameters to improve real-world transfer.

**Dynamical System**: A system in which a function describes the time dependence of a point in an ambient space, fundamental to robot motion modeling.

## E

**Embodied AI**: Artificial intelligence systems that interact with the physical world through a body or robot platform.

**Embodied Cognition**: The idea that the body influences the mind and that cognitive processes are deeply rooted in bodily interactions with the environment.

**End Effector**: The device at the end of a robot arm designed to interact with the environment, such as a gripper or tool.

**Episodic Memory**: Memory system that stores and retrieves specific events or episodes, important for robot learning and adaptation.

**Ethical AI**: Artificial intelligence systems designed and deployed in accordance with ethical principles and values.

**Euclidean Distance**: The "ordinary" straight-line distance between two points in Euclidean space.

## F

**Feedback Control**: A control system that uses the difference between the desired and actual output to adjust the system's behavior.

**Field of Expertise (FoE)**: The range of tasks, environments, or domains where a robot or AI system can operate effectively.

**Force Control**: Control strategy focusing on regulating the forces applied by a robot to its environment.

**Forward Kinematics**: The use of joint parameters to compute the Cartesian position and orientation of the end effector.

**Fuzzy Logic**: A form of many-valued logic that deals with reasoning that is approximate rather than fixed and exact.

## G

**Gait**: The pattern of movement of the limbs of legged creatures, including robots, during locomotion.

**Gaussian Process**: A stochastic process, a collection of random variables, any finite number of which have a joint Gaussian distribution.

**Generalization**: The ability of a machine learning model to perform well on unseen data, crucial for robot deployment.

**Generative Adversarial Network (GAN)**: A class of machine learning frameworks where two neural networks contest with each other.

**Geometric Algebra**: An extension of vector algebra with additional operations, useful for robotics kinematics.

**Goal-Conditioned Policy**: A policy that learns to reach specific goals, fundamental to robot task learning.

**Gradient Descent**: An optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent.

## H

**Heuristic**: A technique designed for solving a problem more quickly when classic methods are too slow, or for finding an approximate solution when classic methods fail.

**Human-Robot Collaboration (HRC)**: Cooperative interaction between humans and robots working together on shared tasks.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, focusing on design and evaluation of robotic systems for human use.

**Hybrid System**: A dynamical system that exhibits both continuous and discrete dynamic behavior, common in robotics.

## I

**Imitation Learning**: Learning by observing and replicating the behavior of others, important for robot skill acquisition.

**Impedance Control**: A control strategy that regulates the relationship between forces applied to a robot and its resulting motion.

**Inertial Measurement Unit (IMU)**: An electronic device that measures and reports a body's specific force, angular rate, and sometimes the magnetic field surrounding the body.

**Inverse Kinematics**: The mathematical process of calculating the variable joint parameters needed to place the end of a kinematic chain in a given position and orientation.

**Isaac Sim**: NVIDIA's robotics simulation application based on NVIDIA Omniverse, for developing and testing AI-based robots.

## J

**Jacobian Matrix**: A matrix of all first-order partial derivatives of a vector-valued function, used in robotics for relating joint velocities to end-effector velocities.

**Joint Space**: The space defined by the joint angles of a robot, as opposed to Cartesian space.

**Jumping Conclusions**: A cognitive bias where decisions are made based on limited information, relevant for robot decision-making.

## K

**Kalman Filter**: An algorithm that uses a series of measurements observed over time to estimate unknown variables, widely used in robotics for state estimation.

**Kinematics**: The branch of mechanics concerned with the motion of objects without reference to the forces that cause the motion.

**Kinesthetic Teaching**: Teaching a robot by physically guiding its motions, allowing the robot to learn by demonstration.

## L

**Latent Space**: A lower-dimensional space that captures the essential features of high-dimensional data, used in generative models.

**Learning Rate**: A hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated.

**Legged Locomotion**: The ability to move using legs, a complex challenge in humanoid robotics.

**LiDAR**: Light Detection and Ranging, a remote sensing method that uses light in the form of a pulsed laser to measure distances.

**Linear Quadratic Regulator (LQR)**: A type of optimal control that solves the problem of controlling a linear system with a quadratic cost function.

**Locomotion**: The ability to move from one place to another, a fundamental capability for mobile robots.

**Long Short-Term Memory (LSTM)**: A type of recurrent neural network capable of learning long-term dependencies, useful for robot control.

## M

**Manipulation**: The skillful handling of objects, a key capability for humanoid robots.

**Markov Decision Process (MDP)**: A mathematical framework for modeling decision-making in situations where outcomes are partly random and partly under the control of a decision maker.

**Mass Matrix**: In robotics, a matrix that relates generalized forces to generalized accelerations in the robot's dynamic equations.

**Machine Learning (ML)**: The study of computer algorithms that can improve automatically through experience and by the use of data.

**Motion Planning**: The task of breaking down a desired movement task into discrete motions that satisfy movement constraints and possibly optimize some aspect of the movement.

## N

**Navigation**: The process of planning, recording, and controlling the movement of a robot from one location to another.

**Neural Network**: A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics how the human brain operates.

**Newton-Euler Formulation**: A recursive method for computing the dynamics of serial-link manipulators.

**Node**: In ROS, a process that performs computation. Nodes are the fundamental building blocks of ROS applications.

## O

**Occupancy Grid**: A probabilistic representation of space, used in robotics for mapping and navigation.

**Open-Loop Control**: A control system that does not use feedback to determine if its output has achieved the desired goal.

**Operational Space**: The space in which robot tasks are naturally expressed, typically Cartesian space for end-effector positioning.

**Optimization**: The selection of the best element from some set of available alternatives, fundamental to robot control and planning.

**Overfitting**: A modeling error in machine learning that occurs when a function is too closely aligned to a limited set of data points.

## P

**Path Planning**: The computational problem of finding a sequence of valid configurations that moves an object from a source to a destination.

**Perception**: The process of acquiring, interpreting, selecting, and organizing sensory information, crucial for robot autonomy.

**PID Controller**: A control loop feedback mechanism widely used in industrial control systems, consisting of Proportional, Integral, and Derivative terms.

**Planning**: The process of finding a sequence of actions to achieve a goal, fundamental to autonomous robot behavior.

**Point Cloud**: A set of data points in space, typically produced by 3D scanning devices, used for environment modeling.

**Pose**: The position and orientation of a robot or object in space, typically represented by position coordinates and rotation parameters.

**Probabilistic Robotics**: A field that deals with perception and action under uncertainty, using probability theory to model and reason about uncertainty.

**Programming by Demonstration (PbD)**: A technique for teaching robots by showing them how to perform tasks, rather than programming them explicitly.

## Q

**Q-Learning**: A model-free reinforcement learning algorithm to learn quality of actions telling an agent what action to take under what circumstances.

**Quaternion**: A four-dimensional complex number that can be used to represent rotations in 3D space, avoiding gimbal lock.

**Quality of Service (QoS)**: In ROS 2, a set of policies that define how messages are delivered between publishers and subscribers.

## R

**RANSAC**: Random Sample Consensus, an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers.

**Reachability**: The ability of a robot to reach a given point in space with its end effector.

**Reactive System**: A system that responds to changes in its environment, fundamental to robot autonomy.

**Reinforcement Learning (RL)**: A type of machine learning where an agent learns to behave in an environment by performing actions and seeing the results.

**Representation Learning**: A set of techniques that allow a machine to automatically discover the representations needed for feature detection or classification from raw data.

**Robot Operating System (ROS)**: Flexible framework for writing robot software, providing services designed for a heterogeneous computer cluster.

**ROS 2**: The second generation of ROS, designed to be suitable for production systems and to be developed in concert with industrial and academic participants.

**Rigid Body**: An idealization of a solid body in which deformation is neglected, fundamental to robot dynamics.

**RRT (Rapidly-exploring Random Tree)**: A path planning algorithm that builds a tree of possible configurations by randomly exploring the space.

## S

**Sensor Fusion**: The combining of sensory data or data derived from disparate sources such that the resulting information has less uncertainty than would be possible when these sources were used individually.

**Simulation**: The imitation of the operation of a real-world process or system over time, crucial for robot development and testing.

**Singularity**: A configuration in which the robot loses one or more degrees of freedom, making it uncontrollable in certain directions.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Social Robot**: A robot that interacts and communicates with humans or other robots by following social behaviors and norms.

**State Estimation**: The process of estimating the internal state of a system from noisy measurements, fundamental to robot autonomy.

**Supervised Learning**: The machine learning task of learning a function that maps an input to an output based on example input-output pairs.

## T

**Teleoperation**: The remote operation of a robot, typically with force feedback to the operator.

**TensorFlow**: An end-to-end open source platform for machine learning developed by Google.

**Topological Map**: A representation of space that captures the connectivity of places rather than metric information.

**Trajectory**: A time-parameterized path that specifies the position, velocity, and acceleration of a robot over time.

**Transformer Architecture**: A deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data.

**Twist**: In robotics, a 6-element vector combining linear and angular velocity, used to describe motion in 3D space.

## U

**Uncertainty Quantification**: The process of characterizing and reducing uncertainties in both computational and real-world applications, crucial for robot safety.

**Unity**: A cross-platform game engine that can be used for robotics simulation and visualization.

**Unstructured Environment**: An environment that lacks regular, predictable structure, challenging for robot navigation and manipulation.

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model, widely used in ROS.

## V

**Variational Autoencoder (VAE)**: A generative model that learns to encode data into a latent space and decode it back, useful for robot learning.

**Velocity Ellipsoid**: A geometric representation showing the achievable velocities of a robot's end effector in different directions.

**VLA (Vision Language Action)**: Models that integrate visual perception, natural language understanding, and action planning for robotic systems.

**VR (Virtual Reality)**: A simulated experience that can be similar to or completely different from the real world, used for robot teleoperation and training.

## W

**Whole-Body Control**: A control approach that considers the entire robot as a single system, optimizing all degrees of freedom simultaneously.

**Workspace**: The space within which a robot can position its end effector, constrained by the robot's kinematics and joint limits.

**World Model**: An internal representation of the environment that an agent uses to predict the outcomes of its actions.

## X

**Xenopsychology**: The study of alien minds, sometimes applied to understanding artificial intelligence and robot cognition.

## Y

**Yaw**: The rotation around the vertical (Z) axis of a robot or vehicle.

## Z

**Zero Moment Point (ZMP)**: A concept used in robotics and biomechanics to propose a stability criterion for legged robots, indicating where the ground reaction force acts.

**Z-axis**: In a 3D coordinate system, typically the vertical axis pointing upward, used in robotics for height and orientation reference.

---

This glossary provides definitions for the key terminology used throughout the Physical AI and Humanoid Robotics course. As the field continues to evolve, new terms will emerge while existing terms may evolve in meaning. This glossary serves as a foundation for understanding the fundamental concepts that will enable effective communication and collaboration in the field of humanoid robotics.